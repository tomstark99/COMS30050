{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# How are we going to use evaluate the performance? \n",
    "# 1. accuracy\n",
    "from sklearn import metrics\n",
    "# 2. f1 score \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Machine learning models \n",
    "\n",
    "# Linear Regression \n",
    "# url : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SVM\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm\n",
    "\n",
    "# KNN \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Tree\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Logistic Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dep_score = pd.read_csv('../data/0&1/total_has_dep_diag.csv')\n",
    "\n",
    "X_t = total_dep_score.copy()\n",
    "del X_t['has_dep_diag']\n",
    "\n",
    "y_t = total_dep_score['has_dep_diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0             1          1          1          1        1        1\n",
      "1             1          1          1          1        1        1\n",
      "2             1          1          1          1        1        1\n",
      "3             1          1          1          1        1        1\n",
      "4             1          1          0          0        1        1\n",
      "...         ...        ...        ...        ...      ...      ...\n",
      "3038          1          1          1          1        1        1\n",
      "3039          1          1          1          1        1        1\n",
      "3040          0          0          0          0        1        0\n",
      "3041          1          1          1          1        1        1\n",
      "3042          1          1          1          1        0        1\n",
      "\n",
      "[3043 rows x 6 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3038    0\n",
      "3039    0\n",
      "3040    0\n",
      "3041    1\n",
      "3042    0\n",
      "Name: has_dep_diag, Length: 3043, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_t)\n",
    "print(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dep_score = pd.read_csv('../data/0&1/sampled_has_dep_diag.csv')\n",
    "\n",
    "X_s = sampled_dep_score.copy()\n",
    "del X_s['has_dep_diag']\n",
    "\n",
    "y_s = sampled_dep_score['has_dep_diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0            1          1          1          1        1        1\n",
      "1            1          1          1          1        1        1\n",
      "2            1          1          1          1        1        1\n",
      "3            1          1          1          1        1        1\n",
      "4            1          1          1          1        1        1\n",
      "..         ...        ...        ...        ...      ...      ...\n",
      "626          1          1          1          1        1        1\n",
      "627          1          1          1          1        1        1\n",
      "628          1          1          1          1        1        1\n",
      "629          1          1          1          1        0        0\n",
      "630          1          1          1          1        1        1\n",
      "\n",
      "[631 rows x 6 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "626    1\n",
      "627    0\n",
      "628    0\n",
      "629    1\n",
      "630    0\n",
      "Name: has_dep_diag, Length: 631, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_s)\n",
    "print(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 130 tasks      | elapsed:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9200438116100766\n",
      "F1 score macro: 0.4791785510553337\n",
      "F1 score weighted: 0.8817305211094859\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1772 tasks      | elapsed:   11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.0001, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   13.5s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9200438116100766\n",
      "F1 score macro: 0.4791785510553337\n",
      "F1 score weighted: 0.8817305211094859\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   16.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'auto', 'leaf_size': 2, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   17.7s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91894852135816\n",
      "F1 score macro: 0.47888127853881274\n",
      "F1 score weighted: 0.8811835136311121\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7500 candidates, totalling 37500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    3.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-801019aa7650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_model_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best hyper parameters\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_model_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 130 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5789473684210527\n",
      "F1 score macro: 0.3666666666666667\n",
      "F1 score weighted: 0.424561403508772\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 1.0, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:    9.3s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5789473684210527\n",
      "F1 score macro: 0.3666666666666667\n",
      "F1 score weighted: 0.424561403508772\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'brute', 'leaf_size': 2, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5736842105263158\n",
      "F1 score macro: 0.40576856249276033\n",
      "F1 score weighted: 0.4556444975522323\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
