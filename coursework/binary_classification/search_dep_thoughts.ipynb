{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# How are we going to use evaluate the performance? \n",
    "# 1. accuracy\n",
    "from sklearn import metrics\n",
    "# 2. f1 score \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Machine learning models \n",
    "\n",
    "# Linear Regression \n",
    "# url : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SVM\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm\n",
    "\n",
    "# KNN \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Tree\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Logistic Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dep_score = pd.read_csv('../data/0&1/total_dep_thoughts.csv')\n",
    "\n",
    "X_t = total_dep_score.copy()\n",
    "del X_t['dep_thoughts']\n",
    "\n",
    "y_t = total_dep_score['dep_thoughts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0             1          2          1          1        1        2\n",
      "1             2          2          3          3        1        2\n",
      "2             1          0          1          2        1        1\n",
      "3             2          3          3          3        2        3\n",
      "4             2          3          1          1        2        1\n",
      "...         ...        ...        ...        ...      ...      ...\n",
      "1249          2          2          2          2        2        1\n",
      "1250          3          3          1          1        1        2\n",
      "1251          3          0          2          2        2        2\n",
      "1252          2          3          1          1        1        2\n",
      "1253          2          3          1          1        1        2\n",
      "\n",
      "[1254 rows x 6 columns]\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1249    1.0\n",
      "1250    1.0\n",
      "1251    0.0\n",
      "1252    1.0\n",
      "1253    1.0\n",
      "Name: dep_thoughts, Length: 1254, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_t)\n",
    "print(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dep_score = pd.read_csv('../data/0&1/sampled_dep_thoughts.csv')\n",
    "\n",
    "X_s = sampled_dep_score.copy()\n",
    "del X_s['dep_thoughts']\n",
    "\n",
    "y_s = sampled_dep_score['dep_thoughts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0            3          3          2          3        1        2\n",
      "1            2          3          1          1        1        2\n",
      "2            2          3          2          1        2        2\n",
      "3            3          3          1          1        2        1\n",
      "4            2          2          1          1        1        2\n",
      "..         ...        ...        ...        ...      ...      ...\n",
      "119          3          3          2          2        1        1\n",
      "120          3          0          2          2        2        2\n",
      "121          3          3          2          2        3        3\n",
      "122          2          2          3          3        2        2\n",
      "123          2          3          2          3        3        3\n",
      "\n",
      "[124 rows x 6 columns]\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      1.0\n",
      "      ... \n",
      "119    1.0\n",
      "120    0.0\n",
      "121    0.0\n",
      "122    0.0\n",
      "123    0.0\n",
      "Name: dep_thoughts, Length: 124, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_s)\n",
    "print(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  74 tasks      | elapsed:    4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:   27.6s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9628647214854111\n",
      "F1 score macro: 0.4905405405405405\n",
      "F1 score weighted: 0.9446483618897412\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1308 tasks      | elapsed:   20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.0001, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   37.1s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9628647214854111\n",
      "F1 score macro: 0.4905405405405405\n",
      "F1 score weighted: 0.9446483618897412\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   17.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'auto', 'leaf_size': 45, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   22.0s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8169761273209549\n",
      "F1 score macro: 0.46357206194708517\n",
      "F1 score weighted: 0.8666374829127079\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7500 candidates, totalling 37500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 425 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1518 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2045 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2652 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3341 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4110 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4961 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5892 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6905 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7998 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9173 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10428 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11765 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 13182 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 14681 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 16260 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Done 17921 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 19662 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 21485 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 23388 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=-1)]: Done 25373 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 27438 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 29585 tasks      | elapsed: 39.9min\n",
      "[Parallel(n_jobs=-1)]: Done 31812 tasks      | elapsed: 42.9min\n",
      "[Parallel(n_jobs=-1)]: Done 34121 tasks      | elapsed: 45.7min\n",
      "[Parallel(n_jobs=-1)]: Done 36510 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done 37500 out of 37500 | elapsed: 49.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9628647214854111\n",
      "F1 score macro: 0.4905405405405405\n",
      "F1 score weighted: 0.9446483618897412\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  74 tasks      | elapsed:    4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5526315789473685\n",
      "F1 score macro: 0.5447498238195913\n",
      "F1 score weighted: 0.5352917176662587\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 860 tasks      | elapsed:   13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.1, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   30.3s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5526315789473685\n",
      "F1 score macro: 0.5498257839721254\n",
      "F1 score weighted: 0.5442141940216394\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'auto', 'leaf_size': 2, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "F1 score macro: 0.45427059712773993\n",
      "F1 score weighted: 0.47921390778533635\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7500 candidates, totalling 37500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9105 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11697 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14613 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 17853 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 19594 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done 21417 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 23320 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25305 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 27370 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 29517 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Done 31744 tasks      | elapsed: 39.9min\n",
      "[Parallel(n_jobs=-1)]: Done 34053 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=-1)]: Done 36442 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 37500 out of 37500 | elapsed: 45.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 14, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 14, 'n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5789473684210527\n",
      "F1 score macro: 0.5789473684210527\n",
      "F1 score weighted: 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
