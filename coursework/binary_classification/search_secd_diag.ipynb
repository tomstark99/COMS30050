{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# How are we going to use evaluate the performance? \n",
    "# 1. accuracy\n",
    "from sklearn import metrics\n",
    "# 2. f1 score \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Machine learning models \n",
    "\n",
    "# Linear Regression \n",
    "# url : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SVM\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm\n",
    "\n",
    "# KNN \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Tree\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Logistic Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dep_score = pd.read_csv('../data/0&1/total_secd_diag.csv')\n",
    "\n",
    "X_t = total_dep_score.copy()\n",
    "del X_t['secd_diag']\n",
    "\n",
    "y_t = total_dep_score['secd_diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0             2          2          1          1        2        2\n",
      "1             2          1          1          1        2        3\n",
      "2             3          3          3          1        2        2\n",
      "3             1          2          1          1        1        2\n",
      "4             2          3          0          0        2        2\n",
      "...         ...        ...        ...        ...      ...      ...\n",
      "3038          3          3          2          2        2        3\n",
      "3039          2          3          1          1        1        2\n",
      "3040          0          0          0          0        2        0\n",
      "3041          2          3          1          1        1        2\n",
      "3042          1          2          2          2        0        1\n",
      "\n",
      "[3043 rows x 6 columns]\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "3038    0.0\n",
      "3039    0.0\n",
      "3040    0.0\n",
      "3041    1.0\n",
      "3042    0.0\n",
      "Name: secd_diag, Length: 3043, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_t)\n",
    "print(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dep_score = pd.read_csv('../data/0&1/sampled_secd_diag.csv')\n",
    "\n",
    "X_s = sampled_dep_score.copy()\n",
    "del X_s['secd_diag']\n",
    "\n",
    "y_s = sampled_dep_score['secd_diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0            2          3          3          3        0        0\n",
      "1            3          3          1          1        1        0\n",
      "2            1          3          1          1        1        2\n",
      "3            2          2          1          1        2        1\n",
      "4            3          3          1          1        2        3\n",
      "..         ...        ...        ...        ...      ...      ...\n",
      "639          3          3          1          1        3        3\n",
      "640          1          1          1          1        0        0\n",
      "641          2          3          3          3        1        3\n",
      "642          1          3          2          3        2        2\n",
      "643          3          3          1          1        3        3\n",
      "\n",
      "[644 rows x 6 columns]\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      1.0\n",
      "4      0.0\n",
      "      ... \n",
      "639    0.0\n",
      "640    1.0\n",
      "641    1.0\n",
      "642    1.0\n",
      "643    0.0\n",
      "Name: secd_diag, Length: 644, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_s)\n",
    "print(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  74 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:   24.2s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.904709748083242\n",
      "F1 score macro: 0.4749856239217941\n",
      "F1 score weighted: 0.8594482483228958\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1772 tasks      | elapsed:   12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.0001, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   14.5s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.904709748083242\n",
      "F1 score macro: 0.4749856239217941\n",
      "F1 score weighted: 0.8594482483228958\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   16.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'ball_tree', 'leaf_size': 23, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   18.5s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9036144578313253\n",
      "F1 score macro: 0.47468354430379744\n",
      "F1 score weighted: 0.858901659572698\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7500 candidates, totalling 37500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2892 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3946 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5160 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6538 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8076 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9778 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11640 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13666 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 15852 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18202 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 20712 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 23386 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 26220 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 29218 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 32376 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done 35698 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 37500 out of 37500 | elapsed: 32.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.904709748083242\n",
      "F1 score macro: 0.4749856239217941\n",
      "F1 score weighted: 0.8594482483228958\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 116 tasks      | elapsed:    3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    8.9s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5773195876288659\n",
      "F1 score macro: 0.5751068376068376\n",
      "F1 score weighted: 0.5773195876288659\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1712 tasks      | elapsed:   11.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 1.0, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   14.2s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5618556701030928\n",
      "F1 score macro: 0.561284486657621\n",
      "F1 score weighted: 0.5624268535485645\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'auto', 'leaf_size': 23, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    6.3s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5257731958762887\n",
      "F1 score macro: 0.49203096539162106\n",
      "F1 score weighted: 0.501478789927328\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7500 candidates, totalling 37500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2892 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3946 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5160 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6538 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8076 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9778 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11640 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 13666 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15852 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18202 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 20712 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 23386 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 26220 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 29218 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 32376 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 35698 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 37500 out of 37500 | elapsed: 27.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 16}\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5515463917525774\n",
      "F1 score macro: 0.5500999600159937\n",
      "F1 score weighted: 0.5519408731352821\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
