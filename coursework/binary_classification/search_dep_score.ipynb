{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# How are we going to use evaluate the performance? \n",
    "# 1. accuracy\n",
    "from sklearn import metrics\n",
    "# 2. f1 score \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Machine learning models \n",
    "\n",
    "# Linear Regression \n",
    "# url : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SVM\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm\n",
    "\n",
    "# KNN \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Tree\n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest \n",
    "# url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Logistic Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dep_score = pd.read_csv('../data/0&1/total_dep_score.csv')\n",
    "\n",
    "X_t = total_dep_score.copy()\n",
    "del X_t['dep_score']\n",
    "\n",
    "y_t = total_dep_score['dep_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0             1          1          1          1        1        1\n",
      "1             1          1          1          1        1        1\n",
      "2             1          1          1          1        1        1\n",
      "3             1          1          1          1        1        1\n",
      "4             1          1          0          0        1        1\n",
      "...         ...        ...        ...        ...      ...      ...\n",
      "3038          1          1          1          1        1        1\n",
      "3039          1          1          1          1        1        1\n",
      "3040          0          0          0          0        1        0\n",
      "3041          1          1          1          1        1        1\n",
      "3042          1          1          1          1        0        1\n",
      "\n",
      "[3043 rows x 6 columns]\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "3038    0.0\n",
      "3039    0.0\n",
      "3040    0.0\n",
      "3041    1.0\n",
      "3042    0.0\n",
      "Name: dep_score, Length: 3043, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_t)\n",
    "print(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dep_score = pd.read_csv('../data/0&1/sampled_dep_score.csv')\n",
    "\n",
    "X_s = sampled_dep_score.copy()\n",
    "del X_s['dep_score']\n",
    "\n",
    "y_s = sampled_dep_score['dep_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      comp_week  comp_wend  text_week  text_wend  tv_week  tv_wend\n",
      "0             1          1          1          1        1        1\n",
      "1             1          1          1          1        1        1\n",
      "2             1          1          1          1        1        1\n",
      "3             1          1          1          1        1        1\n",
      "4             1          1          1          1        1        1\n",
      "...         ...        ...        ...        ...      ...      ...\n",
      "1403          1          1          1          1        1        1\n",
      "1404          0          0          1          1        1        1\n",
      "1405          1          1          1          1        1        1\n",
      "1406          1          1          0          0        1        1\n",
      "1407          1          1          1          1        1        1\n",
      "\n",
      "[1408 rows x 6 columns]\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       0.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1403    1.0\n",
      "1404    0.0\n",
      "1405    0.0\n",
      "1406    0.0\n",
      "1407    1.0\n",
      "Name: dep_score, Length: 1408, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_s)\n",
    "print(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  80 tasks      | elapsed:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:   13.9s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7842278203723987\n",
      "F1 score macro: 0.43953345610804173\n",
      "F1 score weighted: 0.6893887285287138\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1772 tasks      | elapsed:   10.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.0001, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   12.9s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7842278203723987\n",
      "F1 score macro: 0.43953345610804173\n",
      "F1 score weighted: 0.6893887285287138\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   24.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'ball_tree', 'leaf_size': 12, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   26.2s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7831325301204819\n",
      "F1 score macro: 0.43918918918918914\n",
      "F1 score weighted: 0.6888487611379177\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7500 candidates, totalling 37500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2892 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3946 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5160 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6538 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8076 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9778 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11640 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13666 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15852 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 18202 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 20712 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 23386 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 26220 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 29218 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 32376 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 35698 tasks      | elapsed: 17.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 37500 out of 37500 | elapsed: 17.9min finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7842278203723987\n",
      "F1 score macro: 0.43953345610804173\n",
      "F1 score weighted: 0.6893887285287138\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.3, random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper_params = [ \n",
    "                        {\n",
    "                        'gamma': np.logspace(-4, -1, 4),\n",
    "                        'C': np.logspace(-3, 1, 5),\n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "svm_model = svm.SVC(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "svm_model_cv = GridSearchCV(estimator = svm_model, \n",
    "                            param_grid = svm_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 116 tasks      | elapsed:    4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 1.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    8.7s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", svm_model_cv.best_params_)\n",
    "svm_y_pred = svm_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4988179669030733\n",
      "F1 score macro: 0.35265072765072764\n",
      "F1 score weighted: 0.3504691270648717\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, svm_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, svm_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_hyper_params = [ \n",
    "                        {\n",
    "                        'C': np.logspace(-4, 2, 7),\n",
    "                        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "log_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "log_model_cv = GridSearchCV(estimator = log_model, \n",
    "                            param_grid = log_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'C': 0.01, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed:   10.7s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", log_model_cv.best_params_)\n",
    "log_y_pred = log_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5035460992907801\n",
      "F1 score macro: 0.33490566037735847\n",
      "F1 score weighted: 0.3372808778268433\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, log_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, log_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, log_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper_params = [ \n",
    "                        {\n",
    "                        'weights' : ['uniform', 'distance'],\n",
    "                        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'leaf_size' : np.linspace(2, 100, 10, dtype=int)\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(y_t.unique()))\n",
    "\n",
    "# set up GridSearchCV()\n",
    "knn_model_cv = GridSearchCV(estimator = knn_model, \n",
    "                            param_grid = knn_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameters {'algorithm': 'auto', 'leaf_size': 12, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 393 out of 400 | elapsed:    8.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "knn_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", knn_model_cv.best_params_)\n",
    "knn_y_pred = knn_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5011820330969267\n",
      "F1 score macro: 0.3380281690140845\n",
      "F1 score weighted: 0.34035893850098226\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, knn_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, knn_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, knn_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper_params = [ \n",
    "                        {\n",
    "                            'n_estimators' : [int(x) for x in np.linspace(5, 50, 5)],\n",
    "                            'criterion' : ['gini', 'entropy'],\n",
    "                            'max_depth' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_split' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'min_samples_leaf' : [int(x) for x in np.linspace(2, 50, 5)],\n",
    "                            'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                            'bootstrap' : [True, False]\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "# specify model\n",
    "\n",
    "# THIS SECTION SHOULD BE CHANGED.\n",
    "# n_neighbors  SHOULD BE MODIFIED TO ANOTHER VALUE DEPENDING ON THE TARGET VALUE.\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "rf_model_cv = GridSearchCV(estimator = rf_model, \n",
    "                            param_grid = rf_hyper_params, \n",
    "                            scoring= 'accuracy', \n",
    "                            cv = folds, \n",
    "                            verbose = 2,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "print(\"best hyper parameters\", rf_model_cv.best_params_)\n",
    "rf_y_pred = rf_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "# f1 score \n",
    "print(\"F1 score macro:\", f1_score(y_test, rf_y_pred, average='macro'))\n",
    "print(\"F1 score weighted:\", f1_score(y_test, rf_y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
